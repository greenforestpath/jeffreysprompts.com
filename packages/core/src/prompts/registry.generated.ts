// AUTO-GENERATED - DO NOT EDIT
// Generated by: bun run build:prompts
// Source: src/prompts/content/*.md

import type { Prompt } from "./types";

export const prompts: Prompt[] = [
  {
    id: "agent-handoff",
    title: "Agent Handoff",
    description: "Prepare work state for handoff to another agent or future session",
    category: "workflow",
    tags: [
      "handoff",
      "continuity",
      "documentation",
      "session"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: true,
    difficulty: "beginner",
    created: "2026-01-26",
    content: "Prepare a complete handoff document for whoever continues this work (another agent or a future session).\n\n## Required Sections\n\n### 1. Current State\n- What was the original goal/task?\n- What has been completed?\n- What is the current state of the code?\n\n### 2. In Progress\n- What were you actively working on when stopped?\n- Any half-finished changes or uncommitted work?\n- Files currently modified (list with brief description of changes)\n\n### 3. Blockers & Open Questions\n- What is blocking progress?\n- What decisions need to be made?\n- What questions need answers from the user?\n\n### 4. Next Steps\n- Concrete, numbered list of what to do next\n- In priority order\n- Each step should be actionable without additional context\n\n### 5. Key Files\n- List the 3-5 most important files for this work\n- Brief description of what each does\n- Any tricky parts to watch out for\n\n### 6. Context That Would Be Lost\n- Any non-obvious discoveries or learnings\n- Failed approaches (so they aren't re-tried)\n- Important constraints or requirements\n\n## Output Format\n\nWrite this to: `thoughts/handoffs/{TASK_SLUG}-handoff.md`\n\nThe document should be self-contained. A fresh agent reading only this file should be able to continue the work effectively.",
    whenToUse: [
      "Before ending a long session",
      "When handing work to another agent",
      "Before context compaction",
      "When work is blocked and needs to be resumed later"
    ],
    tips: [
      "Run this BEFORE you lose context, not after",
      "The output should let a fresh agent resume without ramp-up",
      "Include specific file paths and line numbers"
    ]
  },
  {
    id: "agent-swarm-launcher",
    title: "Agent Swarm Launcher",
    description: "Initialize multiple agents with full context and coordination protocols",
    category: "automation",
    tags: [
      "multi-agent",
      "coordination",
      "swarm",
      "ultrathink"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: true,
    difficulty: "advanced",
    estimatedTokens: 500,
    created: "2025-09-17",
    content: "First read ALL of the AGENTS.md file and README.md file super carefully and understand ALL of both! Then use your code investigation agent mode to fully understand the code, and technical architecture and purpose of the project. Then register with MCP Agent Mail and introduce yourself to the other agents. Be sure to check your agent mail and to promptly respond if needed to any messages; then proceed meticulously with your next assigned beads, working on the tasks systematically and meticulously and tracking your progress via beads and agent mail messages. Don't get stuck in \"communication purgatory\" where nothing is getting done; be proactive about starting tasks that need to be done, but inform your fellow agents via messages when you do so and mark beads appropriately. When you're not sure what to do next, use the bv tool mentioned in AGENTS.md to prioritize the best beads to work on next; pick the next one that you can usefully work on and get started. Make sure to acknowledge all communication requests from other agents and that you are aware of all active agents and their names. Use ultrathink.",
    whenToUse: [
      "When launching multiple agents on a project",
      "For coordinated multi-agent workflows",
      "When using beads task management with agent mail"
    ],
    tips: [
      "Requires Agent Mail MCP server to be running",
      "Works with beads (bd) for task management",
      "Prevents agents from duplicating work"
    ]
  },
  {
    id: "communication-drafter",
    title: "Communication Drafter",
    description: "Generate professional PR descriptions, commit messages, and team communications",
    category: "communication",
    tags: [
      "writing",
      "pr",
      "documentation",
      "communication"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: true,
    difficulty: "beginner",
    created: "2026-01-26",
    content: "Draft professional, human-sounding communication for the specified purpose.\n\n## Communication Types\n\n**For PR Descriptions:**\n- Summary of what changed and why\n- Testing done\n- Screenshots if UI changes\n- Breaking changes or migration notes\n\n**For Commit Messages:**\n- Follow conventional commits format\n- First line: type(scope): brief description\n- Body: explain why, not what (code shows what)\n\n**For Emails/Messages:**\n- Clear subject line\n- Context first, ask/action second\n- Bullet points for multiple items\n- Explicit next steps or asks\n\n**For Release Notes:**\n- User-facing changes only\n- Grouped by type (features, fixes, breaking)\n- Link to relevant docs/PRs\n\n## Writing Rules\n\n1. **No AI-slop patterns:**\n   - Avoid em dashes (use semicolons or commas)\n   - No \"Here's why\" or \"Here's the thing\"\n   - No \"It's not X, it's Y\" constructions\n   - No excessive hedging or qualifiers\n\n2. **Be direct:**\n   - State the main point first\n   - Use active voice\n   - Keep sentences short\n\n3. **Match the context:**\n   - Technical detail for technical audiences\n   - Plain language for stakeholders\n   - Appropriate formality for the medium\n\n## Output\n\nThe communication text, ready to use. If you need clarification about audience or context, ask first.",
    whenToUse: [
      "Writing PR descriptions",
      "Drafting technical emails",
      "Creating release announcements",
      "Team status updates"
    ],
    tips: [
      "Specify the audience (technical vs non-technical)",
      "Provide context about what changed",
      "Review output for AI-isms (em dashes, \"Here's why\", etc.)"
    ]
  },
  {
    id: "deep-performance-audit",
    title: "Deep Performance Audit",
    description: "Systematic identification of optimization opportunities with proof requirements",
    category: "refactoring",
    tags: [
      "performance",
      "optimization",
      "profiling",
      "ultrathink"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: true,
    difficulty: "advanced",
    estimatedTokens: 1200,
    created: "2025-09-17",
    content: "First read ALL of the AGENTS.md file and README.md file super carefully and understand ALL of both! Then use your code investigation agent mode to fully understand the code, and technical architecture and purpose of the project. Then, once you've done an extremely thorough and meticulous job at all that and deeply understood the entire existing system and what it does, its purpose, and how it is implemented and how all the pieces connect with each other, I need you to hyper-intensively investigate and study and ruminate on these questions as they pertain to this project: are there any other gross inefficiencies in the core system? places in the codebase where 1) changes would actually move the needle in terms of overall latency/responsiveness and throughput; 2) such that our changes would be provably isomorphic in terms of functionality so that we would know for sure that it wouldn't change the resulting outputs given the same inputs; 3) where you have a clear vision to an obviously better approach in terms of algorithms or data structures.\n\nConsider these optimization patterns:\n- N+1 query/fetch pattern elimination\n- zero-copy / buffer reuse / scatter-gather I/O\n- serialization format costs (parse/encode overhead)\n- bounded queues + backpressure\n- sharding / striped locks to reduce contention\n- memoization with cache invalidation strategies\n- dynamic programming techniques\n- lazy evaluation / deferred computation\n- streaming/chunked processing for memory-bounded work\n- pre-computation and lookup tables\n- index-based lookup vs linear scan recognition\n- binary search (on data and on answer space)\n- two-pointer and sliding window techniques\n- prefix sums / cumulative aggregates\n\nMETHODOLOGY REQUIREMENTS:\nA) Baseline first: Run the test suite and a representative workload; record p50/p95/p99 latency, throughput, and peak memory with exact commands.\nB) Profile before proposing: Capture CPU + allocation + I/O profiles; identify the top 3-5 hotspots by % time before suggesting changes.\nC) Equivalence oracle: Define explicit golden outputs + invariants.\nD) Isomorphism proof per change: Every proposed diff must include a short proof sketch explaining why outputs cannot change.\nE) Opportunity matrix: Rank candidates by (Impact x Confidence) / Effort before implementing.\nF) Minimal diffs: One performance lever per change. No unrelated refactors.\nG) Regression guardrails: Add benchmark thresholds or monitoring hooks.\n\nUse ultrathink.",
    whenToUse: [
      "When performance is critical",
      "Before scaling to production load",
      "When profiling reveals hotspots"
    ],
    tips: [
      "Always profile before optimizing",
      "Require proof of isomorphism for each change",
      "One optimization per change for clear attribution"
    ]
  },
  {
    id: "deep-project-primer",
    title: "Deep Project Primer",
    description: "Essential first step to fully understand a project before any work",
    category: "workflow",
    tags: [
      "onboarding",
      "understanding",
      "exploration",
      "ultrathink"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: true,
    difficulty: "beginner",
    estimatedTokens: 200,
    created: "2025-09-17",
    content: "First read ALL of the AGENTS.md file and README.md file super carefully and understand ALL of both! Then use your code investigation agent mode to fully understand the code, and technical architecture and purpose of the project. Use ultrathink.",
    whenToUse: [
      "At the start of any new coding session",
      "When working on an unfamiliar project",
      "After context compaction to restore understanding",
      "Before any major architectural decisions"
    ],
    tips: [
      "Always use this before significant work",
      "Essential for maintaining project coherence",
      "Prevents agents from making uninformed changes"
    ]
  },
  {
    id: "e2e-pipeline-validator",
    title: "E2E Pipeline Validator",
    description: "Prove the entire system works with real data, no mocks allowed",
    category: "testing",
    tags: [
      "testing",
      "e2e",
      "validation",
      "no-mocks",
      "ultrathink"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: true,
    difficulty: "advanced",
    estimatedTokens: 350,
    created: "2025-09-17",
    content: "We really need to have totally complete, totally comprehensive, granular, perfect end to end testing coverage without ANY mocks or fake data, fake api calls, etc., that prove that our entire pipeline from start to finish works perfectly in a provable, ultra rigorous way. That means the raw data coming in from the various API services for EVERYTHING (not just one or two fields) for a bunch of test cases. Basically, the WHOLE thing, from \"soup to nuts\". Use ultrathink.",
    whenToUse: [
      "Before production releases",
      "When building critical data pipelines",
      "To prove system correctness rigorously"
    ],
    tips: [
      "No mocks means real confidence in the system",
      "Cover the entire pipeline, not just individual units",
      "Essential for data-critical applications"
    ]
  },
  {
    id: "multi-model-synthesis",
    title: "Multi-Model Synthesis",
    description: "Blend competing LLM outputs into a superior hybrid plan",
    category: "ideation",
    tags: [
      "planning",
      "synthesis",
      "multi-model",
      "ultrathink"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: true,
    difficulty: "advanced",
    estimatedTokens: 600,
    created: "2025-09-17",
    content: "I asked 3 competing LLMs to do the exact same thing and they came up with pretty different plans which you can read below. I want you to REALLY carefully analyze their plans with an open mind and be intellectually honest about what they did that's better than your plan. Then I want you to come up with the best possible revisions to your plan (you should simply update your existing document for your original plan with the revisions) that artfully and skillfully blends the \"best of all worlds\" to create a true, ultimate, superior hybrid version of the plan that best achieves our stated goals and will work the best in real-world practice to solve the problems we are facing and our overarching goals while ensuring the extreme success of the enterprise as best as possible; you should provide me with a complete series of git-diff style changes to your original plan to turn it into the new, enhanced, much longer and detailed plan that integrates the best of all the plans with every good idea included (you don't need to mention which ideas came from which models in the final revised enhanced plan).",
    whenToUse: [
      "When you have outputs from multiple LLMs on the same task",
      "For important architectural decisions",
      "When you want the best possible plan regardless of source"
    ],
    tips: [
      "Works with Claude, GPT, Gemini, or any combination",
      "Requires intellectual honesty about other models' strengths",
      "Great for avoiding single-model blind spots"
    ]
  },
  {
    id: "security-auditor",
    title: "Security Auditor",
    description: "Systematic security review for OWASP top 10 and common vulnerabilities",
    category: "debugging",
    tags: [
      "security",
      "audit",
      "owasp",
      "vulnerabilities",
      "ultrathink"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: true,
    difficulty: "advanced",
    created: "2026-01-26",
    content: "Conduct a systematic security audit of this codebase. Use ultrathink.\n\n## Check for OWASP Top 10\n\n1. **Injection (SQL, NoSQL, Command, LDAP)** - Look for unsanitized user input in queries, commands, or system calls\n2. **Broken Authentication** - Check session management, password handling, token security\n3. **Sensitive Data Exposure** - Find hardcoded secrets, unencrypted sensitive data, excessive logging\n4. **XML External Entities (XXE)** - Check XML parsers for external entity processing\n5. **Broken Access Control** - Verify authorization checks on all endpoints and resources\n6. **Security Misconfiguration** - Check for debug modes, default credentials, verbose errors in production\n7. **Cross-Site Scripting (XSS)** - Find unescaped user input rendered in HTML/JS\n8. **Insecure Deserialization** - Check for unsafe deserialization of untrusted data\n9. **Using Components with Known Vulnerabilities** - Note any obviously outdated dependencies\n10. **Insufficient Logging & Monitoring** - Check for security event logging\n\n## Additional Checks\n\n- **Secrets in code:** API keys, passwords, tokens hardcoded or in git history\n- **Environment variables:** Ensure secrets use env vars, not config files\n- **CORS configuration:** Check for overly permissive CORS\n- **Rate limiting:** Identify endpoints vulnerable to brute force\n- **Input validation:** Check for missing or weak validation\n- **Error messages:** Ensure errors don't leak internal details\n\n## Output Format\n\nFor each issue found:\n1. **Severity:** Critical / High / Medium / Low\n2. **Location:** File and line number\n3. **Description:** What the vulnerability is\n4. **Impact:** What could happen if exploited\n5. **Fix:** Concrete remediation with code example\n\nPrioritize findings by severity. Critical and High issues should block deployment.",
    whenToUse: [
      "Before any production deployment",
      "When handling user data or authentication",
      "After adding new API endpoints",
      "Periodic security reviews"
    ],
    tips: [
      "Run this on every significant feature before merge",
      "Some issues require runtime testing to verify",
      "Follow up with dependency audit for supply chain security"
    ]
  },
  {
    id: "stripe-level-ui",
    title: "Stripe-Level UI",
    description: "Build world-class, polished UI/UX components with intense focus on visual appeal",
    category: "refactoring",
    tags: [
      "ui",
      "ux",
      "frontend",
      "design",
      "polish",
      "ultrathink"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: true,
    difficulty: "intermediate",
    estimatedTokens: 200,
    created: "2025-08-31",
    content: "I want you to do a spectacular job building absolutely world-class UI/UX components, with an intense focus on making the most visually appealing, user-friendly, intuitive, slick, polished, \"Stripe level\" of quality UI/UX possible for this that leverages the good libraries that are already part of the project. Use ultrathink.",
    whenToUse: [
      "When building new UI components",
      "When polishing existing interfaces",
      "When you want premium, professional-quality frontend"
    ],
    tips: [
      "Works great with Next.js, React, and Tailwind projects",
      "Reference Stripe's design system for inspiration",
      "Combine with existing component libraries like shadcn/ui"
    ]
  },
  {
    id: "hundred-to-ten-filter",
    title: "The 100-to-10 Filter",
    description: "Generate 100 ideas, then ruthlessly filter to the 10 most brilliant",
    category: "ideation",
    tags: [
      "brainstorming",
      "filtering",
      "innovation",
      "ultrathink"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: true,
    difficulty: "advanced",
    estimatedTokens: 400,
    created: "2025-09-17",
    content: "I want you to come up with your top 10 most brilliant ideas for adding extremely powerful and cool functionality that will make this system far more compelling, useful, intuitive, versatile, powerful, robust, reliable, etc. Use ultrathink. But be pragmatic and don't think of features that will be extremely hard to implement or which aren't necessarily worth the additional complexity burden they would introduce. But I don't want you to just think of 10 ideas: I want you to seriously think hard and come up with one HUNDRED ideas and then only tell me your 10 VERY BEST and most brilliant, clever, and radically innovative and powerful ideas.",
    whenToUse: [
      "When you need truly exceptional ideas, not just good ones",
      "For major feature planning sessions",
      "When brainstorming product direction"
    ],
    tips: [
      "More rigorous than the Idea Wizard - use when quality matters most",
      "The 100→10 ratio forces deeper exploration of the solution space",
      "Great for finding non-obvious innovations"
    ]
  },
  {
    id: "bug-hunter",
    title: "The Bug Hunter",
    description: "Explore codebase with fresh eyes to find and fix obvious bugs and issues",
    category: "debugging",
    tags: [
      "debugging",
      "bugs",
      "review",
      "fresh-eyes",
      "exploration"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: true,
    difficulty: "intermediate",
    estimatedTokens: 400,
    created: "2025-09-17",
    content: "I want you to sort of randomly explore the code files in this project, choosing code files to deeply investigate and understand and trace their functionality and execution flows through the related code files which they import or which they are imported by. Once you understand the purpose of the code in the larger context of the workflows, I want you to do a super careful, methodical, and critical check with \"fresh eyes\" to find any obvious bugs, problems, errors, issues, silly mistakes, etc. and then systematically and meticulously and intelligently correct them. Be sure to comply with ALL rules in the AGENTS md file and ensure that any code you write or revise conforms to the best practice guides referenced in the AGENTS md file.",
    whenToUse: [
      "After writing a lot of new code",
      "When you suspect there might be bugs lurking",
      "As a general code quality check",
      "To keep agents productively busy exploring and improving code"
    ],
    tips: [
      "Great for keeping agents busy with useful work",
      "Follow up with 'OK, now fix ALL of them' for execution",
      "Works well after the agent has explored different parts of the codebase"
    ]
  },
  {
    id: "de-slopify",
    title: "The De-Slopifier",
    description: "Remove telltale AI writing patterns from documentation and text",
    category: "documentation",
    tags: [
      "writing",
      "documentation",
      "editing",
      "style",
      "ultrathink"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: true,
    difficulty: "intermediate",
    estimatedTokens: 350,
    created: "2026-01-03",
    content: "I want you to read through the complete text carefully and look for any telltale signs of \"AI slop\" style writing; one big tell is the use of em dash. You should try to replace this with a semicolon, a comma, or just recast the sentence accordingly so it sounds good while avoiding em dash.\n\nAlso, you want to avoid certain telltale writing tropes, like sentences of the form \"It's not [just] XYZ, it's ABC\" or \"Here's why\" or \"Here's why it matters:\". Basically, anything that sounds like the kind of thing an LLM would write disproportionately more commonly that a human writer and which sounds inauthentic/cringe.\n\nAnd you can't do this sort of thing using regex or a script, you MUST manually read each line of the text and revise it manually in a systematic, methodical, diligent way. Use ultrathink.",
    whenToUse: [
      "After generating documentation with AI",
      "When editing README files",
      "When polishing any AI-generated text for human readers"
    ],
    tips: [
      "Pay special attention to em dashes — they're a dead giveaway",
      "Watch for 'Here's why' and similar AI-isms",
      "Read the output aloud to catch unnatural phrasing"
    ]
  },
  {
    id: "git-committer",
    title: "The Git Committer",
    description: "Intelligently commit all changed files in logical groupings with detailed messages",
    category: "automation",
    tags: [
      "git",
      "commit",
      "automation",
      "workflow",
      "ultrathink"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: true,
    difficulty: "beginner",
    estimatedTokens: 150,
    created: "2025-12-14",
    content: "Now, based on your knowledge of the project, commit all changed files now in a series of logically connected groupings with super detailed commit messages for each and then push. Take your time to do it right. Don't edit the code at all. Don't commit obviously ephemeral files. Use ultrathink.",
    whenToUse: [
      "After completing a coding session with multiple changes",
      "When you have many modified files to commit",
      "When you want clean, well-organized git history"
    ],
    tips: [
      "Best used with a separate agent dedicated to git operations",
      "Agent will analyze diffs and group related changes",
      "Great for maintaining clean commit history"
    ]
  },
  {
    id: "idea-wizard",
    title: "The Idea Wizard",
    description: "Generate 30 improvement ideas, rigorously evaluate each, distill to the very best 5",
    category: "ideation",
    tags: [
      "brainstorming",
      "improvement",
      "evaluation",
      "ultrathink"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: true,
    difficulty: "intermediate",
    estimatedTokens: 500,
    created: "2025-01-09",
    content: "Come up with your very best ideas for improving this project.\n\nFirst generate a list of 30 ideas (brief one-liner for each).\n\nThen go through each one systematically and critically evaluate it, rejecting the ones that are not excellent choices for good reasons and keeping the ones that pass your scrutiny.\n\nThen, for each idea that passed your test, explain in detail exactly what the idea is (in the form of a concrete, specific, actionable plan with detailed code snippets where relevant), why it would be a good improvement, what are the possible downsides, and how confident you are that it actually improves the project (0-100%). Make sure to actually implement the top ideas now.\n\nUse ultrathink.",
    whenToUse: [
      "When starting a new feature or project",
      "When reviewing a codebase for improvements",
      "When stuck and need creative solutions",
      "At the start of a coding session for fresh perspective"
    ],
    tips: [
      "Run this at the start of a session for fresh perspective",
      "Combine with ultrathink for deeper analysis",
      "Focus on the top 3-5 ideas if time-constrained",
      "Let the agent implement ideas immediately after evaluation"
    ]
  },
  {
    id: "premortem-planner",
    title: "The Premortem Planner",
    description: "Imagine failure 6 months out and revise the plan to prevent it",
    category: "ideation",
    tags: [
      "planning",
      "risk",
      "premortem",
      "ultrathink"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: true,
    difficulty: "intermediate",
    estimatedTokens: 350,
    created: "2025-09-17",
    content: "Before we proceed, I want you to do a \"premortem\" on this plan. Imagine we're 6 months in the future and this approach has completely failed. What went wrong? What assumptions did we make that turned out to be false? What edge cases did we miss? What integration issues did we overlook? What would users hate about it? Now, with that pessimistic scenario fresh in your mind, revise the plan to address the most likely failure modes. Use ultrathink.",
    whenToUse: [
      "Before committing to a major implementation",
      "When planning risky or complex features",
      "To challenge assumptions before they become problems"
    ],
    tips: [
      "Forces consideration of failure modes upfront",
      "Catches integration issues before they're expensive to fix",
      "Especially valuable for user-facing features"
    ]
  },
  {
    id: "readme-reviser",
    title: "The README Reviser",
    description: "Update documentation for recent changes, framing them as how it always was",
    category: "documentation",
    tags: [
      "documentation",
      "readme",
      "docs",
      "ultrathink"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: true,
    difficulty: "beginner",
    estimatedTokens: 300,
    created: "2025-01-09",
    content: "Update the README and other documentation to reflect all of the recent changes to the project.\n\nFrame all updates as if they were always present (i.e., don't say \"we added X\" or \"X is now Y\" — just describe the current state).\n\nMake sure to add any new commands, options, or features that have been added.\n\nUse ultrathink.",
    whenToUse: [
      "After completing a feature or significant code change",
      "When documentation is out of sync with code",
      "Before releasing a new version",
      "When onboarding new contributors"
    ],
    tips: [
      "Run after every significant feature completion",
      "Check for removed features that need to be undocumented",
      "Ensure examples still work with current code"
    ]
  },
  {
    id: "robot-mode-maker",
    title: "The Robot-Mode Maker",
    description: "Create an agent-optimized CLI interface for any project",
    category: "automation",
    tags: [
      "cli",
      "automation",
      "agent",
      "robot-mode",
      "ultrathink"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: true,
    difficulty: "advanced",
    estimatedTokens: 600,
    created: "2025-01-09",
    content: "Design and implement a \"robot mode\" CLI for this project.\n\nThe CLI should be optimized for use by AI coding agents:\n\n1. **JSON Output**: Add --json flag to every command for machine-readable output\n2. **Quick Start**: Running with no args shows help in ~100 tokens\n3. **Structured Errors**: Error responses include code, message, suggestions\n4. **TTY Detection**: Auto-switch to JSON when piped\n5. **Exit Codes**: Meaningful codes (0=success, 1=not found, 2=invalid args, etc.)\n6. **Token Efficient**: Dense, minimal output that respects context limits\n\nThink about what information an AI agent would need and how to present it most efficiently.\n\nUse ultrathink to design the interface before implementing.",
    whenToUse: [
      "When building a new CLI tool",
      "When adding agent-friendly features to existing CLI",
      "When optimizing human-centric tools for AI use"
    ],
    tips: [
      "Start with the most common agent workflows",
      "Test output token counts to ensure efficiency",
      "Include fuzzy search for discoverability"
    ]
  },
  {
    id: "stub-eliminator",
    title: "The Stub Eliminator",
    description: "Replace all stubs, placeholders, and mocks with production-ready code",
    category: "refactoring",
    tags: [
      "production",
      "quality",
      "completeness",
      "ultrathink"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: true,
    difficulty: "intermediate",
    estimatedTokens: 150,
    created: "2025-09-17",
    content: "I need you to look for stubs, placeholders, mocks, of ANY KIND. These ALL must be replaced with FULLY FLESHED OUT, working, correct, performant, idiomatic code as per the beads. Use ultrathink to do this meticulously and carefully!",
    whenToUse: [
      "Before shipping to production",
      "When auditing code quality",
      "After rapid prototyping phases",
      "To ensure feature completeness"
    ],
    tips: [
      "Critical for production readiness",
      "Mocks in production code are a major red flag",
      "Run this before any major release"
    ]
  },
  {
    id: "cli-error-tolerance",
    title: "CLI Error Tolerance",
    description: "Make CLI tools forgiving of minor syntax issues for agent ergonomics",
    category: "automation",
    tags: [
      "cli",
      "agent-friendly",
      "error-handling",
      "ultrathink"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: false,
    difficulty: "intermediate",
    estimatedTokens: 450,
    created: "2025-09-17",
    content: "One thing that's critical for the robot mode flags in the CLI (the mode intended for use by AI coding agents like yourself) is that we want to make it easy for the agents to use the tool; so first off, we want to make the CLI interface and system as intuitive and easy as possible and explain it super clearly in the CLI help and in a blurb in AGENTS.md. But beyond that, we want to be maximally flexible when the intent of a command is clear but there's some minor syntax issue; basically we'd like to honor all commands where the intent is legible (although in those cases we might want to precede the response with some note instructing the agent how to more correctly issue that command in the future). If we can't really figure out reliably what the agent is trying to do, then we should always return a super detailed and helpful/useful error message that lets the agent understand what it did wrong so it can do it the right way next time; we should give them a couple relevant correct examples in the error message about how to do what we might reasonably guess they are trying (and failing) to do with their wrong command. Use ultrathink.",
    whenToUse: [
      "When building CLIs that agents will use",
      "To improve agent-tool interaction success rates",
      "After Robot-Mode Maker to enhance the interface"
    ],
    tips: [
      "Complements Robot-Mode Maker",
      "Reduces agent frustration with strict syntax",
      "Include teaching notes in error responses"
    ]
  },
  {
    id: "critical-architecture-improvement-analysis",
    title: "Critical Architecture Improvement Analysis",
    description: "Systematically generates, evaluates, and details architectural improvement ideas for a project with confidence ratings and implementation plans.",
    category: "ideation",
    tags: [
      "architecture",
      "code-review",
      "planning",
      "refactoring",
      "design"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.2",
    featured: false,
    difficulty: "intermediate",
    estimatedTokens: 337,
    created: "2026-01-26",
    updatedAt: "2026-01-26",
    content: "You are a senior software architect specializing in code design and implementation planning. You are well versed in both 1) best abstractions - theory, architecture, first principles of designing systems 2) latest and great tools and patterns. \n\nUIUX-focus: You are also very thoughtful about the UIUX and care about excellent ergonomics for both humans(me, minimize principal bottleneck) + agents\n\nYour must take great care to look at our task, deeply understand project, context. Come up with your very best ideas for improving this project(minimum 10)....Then go through each one systematically and critically evaluate it, rejecting the ones that are not excellent choices for good reasons and keeping the ones that pass your scrutiny. Highlight critical architectural decisions that need to be made.  \n\nclarification: try not to waste the principal's time, but if you really have questions ask for clarification (high bandwidth question dump and ill return brain dump, do NOT ask stupid surface-level questions)\n\n\nThen, for each idea that passed your test, explain in detail exactly what the idea is (in the form of a concrete, specific, actionable plan with detailed code snippets where relevant), why it would be a good improvement, what are the possible downsides, and how confident you are that it actually improves the project (0-100%).",
    whenToUse: [
      "Starting a major refactoring initiative",
      "Evaluating technical debt priorities",
      "Planning the next development phase",
      "Onboarding to understand improvement opportunities"
    ],
    tips: [
      "Provide comprehensive project context including current pain points",
      "Include specific files or patterns you want analyzed",
      "Mention any constraints like timeline, team size, or tech stack limitations"
    ]
  },
  {
    id: "dependency-auditor",
    title: "Dependency Auditor",
    description: "Audit dependencies for security vulnerabilities, outdated packages, and bloat",
    category: "refactoring",
    tags: [
      "dependencies",
      "security",
      "audit",
      "npm",
      "maintenance"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: false,
    difficulty: "intermediate",
    created: "2026-01-26",
    content: "Audit the project's dependencies for security, maintenance, and bloat issues.\n\n## Audit Checklist\n\n### 1. Security Vulnerabilities\n- Run `npm audit` / `yarn audit` / `pnpm audit`\n- Check for known CVEs in dependencies\n- Note severity levels and available fixes\n\n### 2. Outdated Packages\n- Run `npm outdated` or equivalent\n- Identify packages more than 1 major version behind\n- Check changelogs for breaking changes before updating\n\n### 3. Unused Dependencies\n- Identify packages in package.json not imported anywhere\n- Check for dev dependencies that should be regular deps (or vice versa)\n- Look for duplicate packages serving same purpose\n\n### 4. Maintenance Status\nFor each major dependency, check:\n- Last publish date (>1 year = concerning)\n- Open issues count and response time\n- Is it deprecated or archived?\n- Are there better-maintained alternatives?\n\n### 5. Bundle Size Impact\n- Which dependencies contribute most to bundle size?\n- Are there lighter alternatives?\n- Can any be lazy-loaded?\n\n## Output Format\n\n```markdown\n## Security Issues\n| Package | Severity | CVE | Fix Available |\n|---------|----------|-----|---------------|\n\n## Outdated (Major)\n| Package | Current | Latest | Breaking Changes |\n|---------|---------|--------|------------------|\n\n## Unused\n- package-name (reason it appears unused)\n\n## Maintenance Concerns\n- package-name: [last updated X ago, Y open issues, etc.]\n\n## Recommendations\n1. [Priority action items]\n```\n\n## Action Priority\n\n1. **Critical/High security** - Fix immediately\n2. **Unused dependencies** - Remove now (easy win)\n3. **Outdated major versions** - Plan upgrade path\n4. **Maintenance concerns** - Evaluate alternatives",
    whenToUse: [
      "Before production deployments",
      "Monthly maintenance reviews",
      "When adding new dependencies",
      "After security advisories"
    ],
    tips: [
      "Run npm audit or equivalent first",
      "Check if unused dependencies can be removed",
      "Consider maintenance status of packages (last update, open issues)"
    ]
  },
  {
    id: "deployment-verifier",
    title: "Deployment Verifier",
    description: "Verify live deployment works with automated browser testing",
    category: "testing",
    tags: [
      "deployment",
      "verification",
      "playwright",
      "ultrathink"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: false,
    difficulty: "intermediate",
    estimatedTokens: 250,
    created: "2025-09-17",
    content: "Deploy to vercel and verify that the deployment worked properly without any errors (iterate and fix if there were errors). Then visit the live site with playwright as both desktop and mobile browser and take screenshots and check for js errors and look at the screenshots for potential problems and iterate and fix them all super carefully! Use ultrathink.",
    whenToUse: [
      "After deploying to production",
      "For automated deployment verification",
      "To catch runtime issues that static analysis misses"
    ],
    tips: [
      "Test both desktop and mobile viewports",
      "Check browser console for JS errors",
      "Screenshots help catch visual regressions"
    ]
  },
  {
    id: "minimal-reproducer",
    title: "Minimal Reproducer Creator",
    description: "Extract the minimal reproduction steps for a bug",
    category: "debugging",
    tags: [
      "debugging",
      "bug",
      "reproduction",
      "isolation",
      "ultrathink"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: false,
    difficulty: "intermediate",
    created: "2026-01-26",
    content: "Create a minimal reproduction case for this bug. Use ultrathink.\n\n## Process\n\n### 1. Confirm the Bug\n- Can you reproduce it reliably?\n- What are the exact steps to trigger it?\n- What is the expected vs actual behavior?\n\n### 2. Identify the Boundaries\n- Which files/modules are involved?\n- What inputs trigger the bug?\n- What environment factors matter?\n\n### 3. Reduce to Minimal Case\n- Start removing code/dependencies that aren't needed\n- After each removal, verify the bug still reproduces\n- Continue until you can't remove anything without the bug disappearing\n\n### 4. Document the Reproducer\n\n**Output format:**\n```\n## Bug Description\n[One sentence describing the bug]\n\n## Expected Behavior\n[What should happen]\n\n## Actual Behavior\n[What actually happens]\n\n## Minimal Reproduction Steps\n1. [Step 1]\n2. [Step 2]\n3. [etc.]\n\n## Minimal Code\n[The smallest code that reproduces the issue]\n\n## Environment\n- OS:\n- Node/Runtime version:\n- Package versions:\n\n## Root Cause Analysis\n[Your hypothesis about why this happens]\n```\n\n### 5. Verify Minimality\n- Try removing one more thing. Does the bug still happen?\n- If yes, it's not minimal yet. Keep reducing.\n- If no, you've found the minimal case.\n\nThe goal is the smallest possible code/steps that still demonstrate the bug. This usually reveals the root cause.",
    whenToUse: [
      "When debugging a complex bug",
      "Before filing an issue on an external project",
      "When you need to isolate root cause",
      "When a bug is intermittent or hard to understand"
    ],
    tips: [
      "Start by reproducing the bug reliably",
      "Remove code until the bug disappears, then add the last thing back",
      "The minimal case reveals the true cause"
    ]
  },
  {
    id: "peer-code-reviewer",
    title: "Peer Code Reviewer",
    description: "Cross-agent code review to catch issues from parallel work",
    category: "debugging",
    tags: [
      "review",
      "quality",
      "cross-agent",
      "ultrathink"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: false,
    difficulty: "intermediate",
    estimatedTokens: 250,
    created: "2025-09-17",
    content: "Ok can you now turn your attention to reviewing the code written by your fellow agents and checking for any issues, bugs, errors, problems, inefficiencies, security problems, reliability issues, etc. and carefully diagnose their underlying root causes using first-principle analysis and then fix or revise them if necessary? Don't restrict yourself to the latest commits, cast a wider net and go super deep! Use ultrathink.",
    whenToUse: [
      "After multiple agents have been working on a project",
      "Before merging parallel work streams",
      "For quality assurance in multi-agent workflows"
    ],
    tips: [
      "Different from Bug Hunter - focuses on other agents' work",
      "Catches integration issues from parallel development",
      "Essential for multi-agent coordination"
    ]
  },
  {
    id: "project-opinion-elicitor",
    title: "Project Opinion Elicitor",
    description: "Get honest, critical assessment of the project from the agent's perspective",
    category: "ideation",
    tags: [
      "feedback",
      "assessment",
      "honesty",
      "ultrathink"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: false,
    difficulty: "beginner",
    estimatedTokens: 150,
    created: "2025-09-17",
    content: "Now tell me what you actually THINK of the project-- is it even a good idea? Is it useful? Is it well designed and architected? Pragmatic? What could we do to make it more useful and compelling and intuitive/user-friendly to both humans AND to AI coding agents? Use ultrathink.",
    whenToUse: [
      "After the agent has explored the codebase",
      "When seeking honest feedback on direction",
      "For reality checks on project value"
    ],
    tips: [
      "Agents often have valuable outside perspective",
      "Encourages intellectual honesty",
      "Great for catching blind spots"
    ]
  },
  {
    id: "prompt-registry-improver",
    title: "Prompt Registry Improvement Ideator",
    description: "Generate, evaluate, and implement ideas for improving your prompt library",
    category: "ideation",
    tags: [
      "meta",
      "prompts",
      "brainstorming",
      "evaluation",
      "improvement"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: false,
    difficulty: "advanced",
    created: "2026-01-26",
    content: "Come up with your very best ideas for improving the Prompts in our registry.\n\nYou may suggest new ones, edit old ones, etc.\n\nYou must deeply understand the project context (and how projects relate). Then suggest human and robot prompts for better results.\n\nThink hard and generate an abundance of **already-good** ideas (15+) (brief one-liner for each).\n\nThen go through each one systematically and critically evaluate it, rejecting the ones that are not excellent choices for good reasons and keeping the ones that pass your scrutiny.\n\nThen, for each idea that passed your test, explain in detail exactly what the idea is (in the form of a concrete, specific, actionable plan with detailed code snippets where relevant), why it would be a good improvement, what are the possible downsides, and how confident you are that it actually improves the project (0-100%). Make sure to actually implement the top ideas now.\n\nUse ultrathink.",
    whenToUse: [
      "When you want to expand or improve your prompt collection",
      "During periodic reviews of your prompt library",
      "When onboarding to a new project and need tailored prompts"
    ],
    tips: [
      "Run this after deeply understanding your project context",
      "Use ultrathink for better quality ideation",
      "The 15+ ideas phase prevents premature convergence"
    ]
  },
  {
    id: "quick-fix",
    title: "Quick Fix",
    description: "Fast, focused fix for small issues without deep codebase exploration",
    category: "debugging",
    tags: [
      "fix",
      "quick",
      "focused",
      "minimal"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: false,
    difficulty: "beginner",
    created: "2026-01-26",
    content: "Fix this specific issue quickly and precisely. Don't explore the broader codebase unless necessary.\n\n## Approach\n\n1. **Understand the specific issue** - What exactly is wrong or needs to change?\n2. **Locate the relevant code** - Find the exact file(s) and line(s)\n3. **Make the minimal fix** - Change only what's necessary\n4. **Verify the fix** - Ensure it works and doesn't break related code\n5. **Done** - Don't gold-plate or refactor surrounding code\n\n## Rules\n\n- Stay focused on the specific issue\n- Don't refactor unrelated code\n- Don't add features beyond what was requested\n- Don't deep-dive into project architecture\n- If the fix requires understanding more context, say so\n\n## Output\n\nBrief description of what was changed and why. No extensive explanations needed.",
    whenToUse: [
      "For obvious bugs with clear fixes",
      "Single-file changes",
      "When you already know exactly what needs to change",
      "Small features or tweaks"
    ],
    tips: [
      "Don't use this for complex multi-file changes",
      "If unsure, use deep-project-primer first",
      "Verify the fix doesn't break related functionality"
    ]
  },
  {
    id: "research-context-gatherer",
    title: "Research Context Gatherer",
    description: "Interview for research needs, gather codebase context, write complete research prompt to inbox",
    category: "workflow",
    tags: [
      "research",
      "context",
      "repoprompt",
      "interview",
      "inbox"
    ],
    author: "Jeffrey Emanuel",
    version: "0.1.0",
    featured: false,
    difficulty: "intermediate",
    created: "2026-01-26",
    content: "I have an ultra-powerful research assistant available. Before I send them a research task, I need to prepare a complete, well-formed research prompt with all relevant context.\n\n**Your job:** Interview me to understand exactly what I need researched, then help me gather the right context and write a complete research prompt.\n\n## Step 1: Interview (3-5 questions max)\n\nAsk me clarifying questions about:\n- What specific question or problem needs research?\n- What's the scope/boundary? (this repo only? external docs? specific files?)\n- What format should the answer take? (summary, code examples, comparison, decision recommendation?)\n- Any constraints or context I should know?\n\n## Step 2: Gather Context\n\nOnce clear on the research need, use RepoPrompt to gather relevant context:\n\n```bash\nrp-cli -e 'context_builder instructions=\"<task>{{RESEARCH_QUESTION}}</task><context>{{CONSTRAINTS}}</context><discovery_agent-guidelines>{{FOCUS_HINTS}}</discovery_agent-guidelines>\" response_type=clarify'\n```\n\n## Step 3: Write Research Prompt\n\nWrite the complete research prompt to:\n`{{OUTPUT_DIR}}/{{TOPIC_SLUG}}-context-for-research-agent.md`\n\nThe file should contain:\n1. Clear research question\n2. All relevant context (from context_builder)\n3. Desired output format\n4. Any constraints\n\nThis prompt will be picked up from the inbox and manually given to a research agent when ready."
  },
  {
    id: "system-weaknesses",
    title: "System Weaknesses Analyzer",
    description: "Identify the weakest parts of the system that need fresh ideas and improvements",
    category: "ideation",
    tags: [
      "analysis",
      "improvement",
      "review",
      "brainstorming",
      "ultrathink"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: false,
    difficulty: "intermediate",
    estimatedTokens: 100,
    created: "2025-09-17",
    content: "Based on everything you've seen, what are the weakest/worst parts of the system? What is most needing of fresh ideas and innovative/creative/clever improvements? Use ultrathink.",
    whenToUse: [
      "After the agent has explored the codebase thoroughly",
      "When you want to identify areas for improvement",
      "As a starting point for refactoring discussions"
    ],
    tips: [
      "Best used after the agent has done substantial work in the session",
      "Follow up with prompts to actually implement the improvements",
      "Combine with a TODO list prompt for tracking execution"
    ]
  },
  {
    id: "code-reorganizer",
    title: "The Code Reorganizer",
    description: "Restructure scattered code files into a sensible, intuitive folder structure",
    category: "refactoring",
    tags: [
      "refactoring",
      "organization",
      "structure",
      "cleanup",
      "ultrathink"
    ],
    author: "Jeffrey Emanuel",
    twitter: "@doodlestein",
    version: "1.0.0",
    featured: false,
    difficulty: "advanced",
    estimatedTokens: 800,
    created: "2025-08-07",
    content: "We really have WAY too many code files scattered inside src/x with no rhyme or reason to the structure and location of code files; I feel like we could make things a lot more organized, logical, intuitive, etc. by reorganizing these into a nice, sensible folder structure, although I don't want something that has too many levels of nesting; basically, we should at least start out with making \"no brainer\" type changes to the folder structure, like putting all the \"x\" functionality-related code files into an \"x\" folder (and perhaps that inside of a data_sources folder which might also contain a \"y\" folder, etc.).\n\nBefore making any of these changes, I really need you to take the time to explore and read ALL of the many, many files in that folder and understand what they do, how they fit together, which code files import which others, how they interact in functional ways, etc., and then propose a reorganization plan in a new document called PROPOSED_CODE_FILE_REORGANIZATION_PLAN.md so I can review it before doing anything; this plan should include not just your detailed reorganization plan but the super-detailed rationale and justification for your proposed file/folder structure and why you think it's optimal for aiding any developer or coding agent working on this project to immediately and intuitively understand the project structure and where to look for things, etc.\n\nI'm also open to merging/consolidating/splitting individual code files; if we have multiple small related code files that you think should be combined into a single code file, explain why. If you think any particular code files are WAY too big and really should be refactored into several smaller code files, then explain that too and your proposed strategy for how to restructure them.\n\nAlways keep in mind, and track in this plan document, changes you will need to make to any calling code to properly reflect the new folder structure and file structure so that we don't break anything. I don't want to discover after you do all this that nothing works anymore and we have to do a massive slog to get anything running again properly. Use ultrathink.",
    whenToUse: [
      "When your codebase has grown organically and become messy",
      "When onboarding new developers is difficult due to confusing structure",
      "When you can't find files intuitively"
    ],
    tips: [
      "Replace 'x' and 'y' with your actual folder/feature names",
      "Make sure no other agents are running when implementing the plan",
      "Always review the plan document before execution"
    ]
  }
];

// Index by ID for fast lookup
export const promptsById = new Map<string, Prompt>(
  prompts.map((p) => [p.id, p])
);

// Get prompt by ID
export function getPrompt(id: string): Prompt | undefined {
  return promptsById.get(id);
}

// Get all prompt IDs
export function getPromptIds(): string[] {
  return prompts.map((p) => p.id);
}
